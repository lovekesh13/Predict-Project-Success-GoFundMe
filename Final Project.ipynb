{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/thomas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('gofundme.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 408 entries, 0 to 407\n",
      "Data columns (total 14 columns):\n",
      "web-scraper-order        408 non-null object\n",
      "web-scraper-start-url    408 non-null object\n",
      "url                      408 non-null object\n",
      "url-href                 408 non-null object\n",
      "post_name                408 non-null object\n",
      "story                    404 non-null object\n",
      "amount_donated           408 non-null object\n",
      "amount_goal              408 non-null object\n",
      "donatedby_pplcount       405 non-null object\n",
      "likes                    405 non-null object\n",
      "shares                   401 non-null object\n",
      "location                 405 non-null object\n",
      "post_created_on          405 non-null object\n",
      "image-src                348 non-null object\n",
      "dtypes: object(14)\n",
      "memory usage: 44.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_missing(df):\n",
    "    known = df[df.story.notnull()]\n",
    "    unknown = df[df.story.isnull()]\n",
    "    var = known.columns.tolist()\n",
    "    X = known.loc[:, var ].drop('story',axis = 1)\n",
    "    y = known['story']\n",
    "    # replace predicted values\n",
    "    predicted = ' '\n",
    "    df.loc[(df.story.isnull()), 'story'] = predicted\n",
    "    return df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 408 entries, 0 to 407\n",
      "Data columns (total 14 columns):\n",
      "web-scraper-order        408 non-null object\n",
      "web-scraper-start-url    408 non-null object\n",
      "url                      408 non-null object\n",
      "url-href                 408 non-null object\n",
      "post_name                408 non-null object\n",
      "story                    408 non-null object\n",
      "amount_donated           408 non-null object\n",
      "amount_goal              408 non-null object\n",
      "donatedby_pplcount       405 non-null object\n",
      "likes                    405 non-null object\n",
      "shares                   401 non-null object\n",
      "location                 405 non-null object\n",
      "post_created_on          405 non-null object\n",
      "image-src                348 non-null object\n",
      "dtypes: object(14)\n",
      "memory usage: 44.7+ KB\n"
     ]
    }
   ],
   "source": [
    "set_missing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(dataframe,column):\n",
    "    captions = []\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        captions.append(pd.DataFrame(dataframe.iloc[:][column]).loc[i][0].lower())\n",
    "    wordcount = Counter(pos_tag(word_tokenize(''.join(captions))))\n",
    "    word_list = sorted(list(wordcount.items()), key = lambda w: -w[1])\n",
    "    stoplist = nltk.corpus.stopwords.words('english')\n",
    "    word_list = [word_list[i] for i in range(len(word_list)) \n",
    "                 if len(word_list[i][0][0]) > 2 and word_list[i][0][0] not in stoplist \n",
    "                 and word_list[i][0][1] in ['NN', 'NNP', 'NNS', 'JJ']]\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-848faf68dbfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcount_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'post_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'count_words' is not defined"
     ]
    }
   ],
   "source": [
    "count_words(data, 'post_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from math import log\n",
    "# import numpy as np\n",
    "# import csv\n",
    "# import re\n",
    "# from collections import namedtuple\n",
    "\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "def get_story_sentiment_score(stories):\n",
    "    sentiments = []\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    for story in stories:\n",
    "        story_sentiment = analyser.polarity_scores(story)['compound']\n",
    "        sentiments.append(story_sentiment)\n",
    "    return sentiments\n",
    "\n",
    "data['sentiment'] = get_story_sentiment_score(data['story'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Length of description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['story_length'] = [len(story) for story in data['story']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Money transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['amount_donated'] = [int(amount[1:].replace(',','')) for amount in data['amount_donated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = []\n",
    "\n",
    "for gathered in data['amount_goal']:\n",
    "    if gathered == 'raised':\n",
    "        goal.append(data['amount_donated'])\n",
    "    else:\n",
    "        a = gathered[4:-5].replace(',','')\n",
    "        if 'M' in a:\n",
    "            b = int(a[:-1].replace('.',''))*100000\n",
    "            goal.append(b)\n",
    "        else:\n",
    "            goal.append(int(a))\n",
    "\n",
    "\n",
    "data['amount_goal'] = goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['percentage'] = data['amount_donated'] / data['amount_goal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import vision\n",
    "import csv\n",
    "import urllib.request\n",
    "import time\n",
    "\n",
    "DAYS_GRAPH_MAX = 730\n",
    "MAX_POSTS = 10\n",
    "DONATIONS_URL = 'https://www.gofundme.com/mvc.php?route=donate/pagingDonationsFoundation&url={}&idx={}&type=recent'\n",
    "\n",
    "class Donation:\n",
    "    def __init__(self, time_raised, amount):\n",
    "        self.time_raised = time_raised\n",
    "        self.amount = amount\n",
    "\n",
    "class Fundraise:\n",
    "    def __init__(self, id, start_url, url, post_name, story, amount_donated, amount_goal, amount_donators, likes, shares, location, created_date, post_image):\n",
    "        self.id = id\n",
    "        self.start_url = start_url\n",
    "        self.url = url\n",
    "        self.post_name = post_name\n",
    "        self.story = story\n",
    "        self.amount_donated = amount_donated\n",
    "        self.amount_goal = amount_goal\n",
    "        self.amount_donators = amount_donators\n",
    "        self.likes = likes\n",
    "        self.shares = shares\n",
    "        self.location = location\n",
    "        self.created_date = created_date\n",
    "        self.post_image = post_image\n",
    "        self.image_labels = []\n",
    "\n",
    "donations = []\n",
    "\n",
    "\n",
    "def import_scraped_posts(file_path):\n",
    "    post_counter = 0\n",
    "    fundraises = []\n",
    "    with open(file_path,'r', encoding=\"utf8\") as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            if post_counter > MAX_POSTS:\n",
    "                break\n",
    "            fundraise = Fundraise(row[0],row[1],row[3],row[4],row[5],re.sub('[^0-9]','', row[6]),re.sub('[^0-9]','', row[7]),row[8],row[9],row[10],row[11],row[12],row[13])\n",
    "            fundraises.append(fundraise)\n",
    "            post_counter += 1\n",
    "    return fundraises\n",
    "\n",
    "def normalize_time_raised(time_raised):\n",
    "    time_raised_str = time_raised\n",
    "    if 'hours' in time_raised_str:\n",
    "        time_raised = 0\n",
    "    p = re.compile(r\"\\d+\")\n",
    "    match = p.match(time_raised)\n",
    "    if match:\n",
    "        time_raised = int(match[0])\n",
    "    if 'month' in time_raised_str:\n",
    "        time_raised = time_raised * 30\n",
    "    return time_raised\n",
    "\n",
    "def analyze_donation_times(donations):\n",
    "    days_graph = [0] * DAYS_GRAPH_MAX\n",
    "    for i in range(len(donations)):\n",
    "        time_raised = donations[i].time_raised\n",
    "        time_raised = normalize_time_raised(time_raised)\n",
    "        donations[i].time_raised = time_raised\n",
    "\n",
    "    for donation in donations:\n",
    "        if donation.time_raised < DAYS_GRAPH_MAX:\n",
    "            days_graph[donation.time_raised] += 1\n",
    "    return days_graph\n",
    "\n",
    "def plot_donations_graph(days_graph):\n",
    "    plt.plot(days_graph)\n",
    "    plt.ylabel('donators')\n",
    "    plt.xlabel('days')\n",
    "    plt.show()\n",
    "\n",
    "def get_posts_attrs(fundraises):\n",
    "    credentials = service_account.Credentials.from_service_account_file('UGCA-f6b4b2de52f8.json')\n",
    "    client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "    image = vision.types.Image()\n",
    "    for fundraise in fundraises:\n",
    "        if fundraise.post_image == '':\n",
    "            continue\n",
    "        else:\n",
    "            image.source.image_uri = fundraise.post_image\n",
    "            response = client.label_detection(image=image)\n",
    "            fundraise.image_labels = [label.description for label in response.label_annotations]\n",
    "\n",
    "def extract_donations(html):\n",
    "    donation_times = []\n",
    "    start_index = 0\n",
    "    end_index = 0\n",
    "    while True:\n",
    "        end_index = html.find('ago',end_index+1)\n",
    "        if end_index == -1:\n",
    "            break\n",
    "        start_index = end_index - 10\n",
    "        if start_index < 0:\n",
    "            start_index = 0\n",
    "        p = re.compile(r\"[0-9]+? [a-z]{3,8}\")\n",
    "        match = p.match(html[start_index:end_index])\n",
    "        if not match:\n",
    "            continue\n",
    "        donation_time = normalize_time_raised(match[1])\n",
    "        donation_times.append(donation_time)\n",
    "\n",
    "    #donation_time_strs = re.findall(r\"([0-9]+? [a-z]{3,8}) ago\", html)\n",
    "    #donation_times = [normalize_time_raised(donation_time_str) for donation_time_str in donation_time_strs]\n",
    "    return donation_times\n",
    "\n",
    "def get_fundraise_donations(fundraise,project_url_name):\n",
    "    donation_times = []\n",
    "    index = 0\n",
    "\n",
    "    response = urllib.request.urlopen(DONATIONS_URL.format(project_url_name, index))\n",
    "    html = str(response.read())\n",
    "    while len(html)>800:\n",
    "        start_time = time.time()\n",
    "        response = urllib.request.urlopen(DONATIONS_URL.format(project_url_name,index))\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        html = str(response.read())\n",
    "        donation_times.extend(extract_donations(html))\n",
    "        index += 10\n",
    "    return donation_times\n",
    "\n",
    "def get_donation_times(fundraises):\n",
    "    donation_times = []\n",
    "    i=0\n",
    "    fundraises.sort(key= lambda fundraise: fundraise.amount_donated, reverse=True)\n",
    "    while i in range (1) and i in range(len(fundraises)):\n",
    "        p = re.compile(r\".*?\\/([^\\/]*)$\")\n",
    "        match = p.match(fundraises[i].url)\n",
    "        if match:\n",
    "            project_url_name = match[1]\n",
    "        else:\n",
    "            i += 1\n",
    "            continue\n",
    "        donation_times.extend(get_fundraise_donations(fundraises[i],project_url_name))\n",
    "        i += 1\n",
    "\n",
    "    return donation_times\n",
    "\n",
    "\n",
    "fundraises = import_scraped_posts('gofundme.csv')\n",
    "#donation_times = get_donation_times(fundraises)\n",
    "#print(donation_times)\n",
    "get_posts_attrs(fundraises)\n",
    "\n",
    "print(fundraises[0].image_labels)\n",
    "\n",
    "days_graph = analyze_donation_times(donations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/thomas/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_labels = [fundraises[i].image_labels for i in range(len(fundraises))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels = {}\n",
    "for i in range(len(post_labels)):\n",
    "    for j in range(len(post_labels[i])):\n",
    "        if post_labels[i][j] in dict_labels:\n",
    "            a = dict_labels[post_labels[i][j]] + 1\n",
    "            dict_labels[post_labels[i][j]] = a\n",
    "        else:\n",
    "            dict_labels[post_labels[i][j]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'sklearn.lda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-284-ab21cee528cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'sklearn.lda'"
     ]
    }
   ],
   "source": [
    "import sklearn.lda\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: failed\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - lda\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/conda-forge/osx-64\n",
      "  - https://conda.anaconda.org/conda-forge/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/free/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/free/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "  - https://repo.anaconda.com/pkgs/pro/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/pro/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = pd.read_csv('names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_of_names = set(names['name'])\n",
    "# months = ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "#           'July', 'August', 'September', 'October', 'November', 'December']\n",
    "# family_related = ['aunt', 'brother', 'cousin', 'daughter', 'father', 'grandchild',\n",
    "#                   'granddaughter', 'grandson', 'grandfather', 'granddmother', \n",
    "#                   'great-grandchild', 'husband', 'ex-husband', 'in-laws', 'son-in-law',\n",
    "#                   'daughter-in-law', 'mother', 'niece', 'nephew', 'parents', 'sister',\n",
    "#                   'son', 'stepfather', 'stepmother', 'stepdaughter', 'stepson', 'twin',\n",
    "#                   'uncle', 'widow', 'widower', 'wife', 'ex-wife']\n",
    "# possesive_words = ['he', 'she', 'they', 'my', 'mine', 'our', 'ours', 'his', 'her']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# personal = []\n",
    "\n",
    "# for story in data['story']:\n",
    "#     count_name = 0\n",
    "#     count_date = 0\n",
    "#     count_fami = 0\n",
    "#     count_poss = 0\n",
    "#     for name in set_of_names:\n",
    "#         if name in story:\n",
    "#             count_name += 1\n",
    "#     for month in months:\n",
    "#         if month in story:\n",
    "#             count_date +=1\n",
    "#     for f in family_related:\n",
    "#         if f in story:\n",
    "#             count_fami +=1    \n",
    "#     for p in possesive_words:\n",
    "#         if p in story:\n",
    "#             count_poss +=1  \n",
    "#     if count_name > 0 and count_date > 0 and count_fami > 0 and count_poss > 0:\n",
    "#         personal.append(1)\n",
    "\n",
    "#     else:\n",
    "#         personal.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
